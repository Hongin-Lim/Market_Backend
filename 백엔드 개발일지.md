# 백엔드 개발일지


#### < 1주차 >

- 쿠버네티스 컨테이너디 환경 세팅 ( 완료 )
- ELK 설치 ( 완료 )
- 파이프라인 시나리오 작성 ( 진행중 ) 
- 카프카 올리기 ( 완료 )
- 하둡 이미지 빌드하기 ( 완료 )
- 하둡 이미지 위에 스파크 올려서 이미지 빌드하기 ( 완료 )
- 하둡 + 스파크 이미지 올리기 ( 완료 )
- 하둡 + 스파크 이미지 위에 제플린 올려서 이미지 빌드하기 ( 완료 )
- 하둡 + 스파크 + 제플린 이미지 사용해서 디플로이먼트 올리기 ( 완료 )
- 쿠버네티스 디플로이먼트 포트포워딩 고려 ( 추후과제 )
- 프로그램 개발환경 테스트 ( 진행중 )
- 프로그램들 모두 연결하기 ( 추후과제 )
- 쿠버네티스 컨테이너 기능들 추가해보기 ( 보류 )




**2022 / 05 / 03**

- Containerd 설치
- Kubernetes 설치

	master node 1대  
	worker node 5대

	master 172.30.1.222  
	worker1 172.30.1.2  
	worker2 172.30.1.62  
	worker3 172.30.1.129  
	worker4 172.30.1.144  
	worker5 172.30.1.194  

▶ 오늘의 오류 발생 및 해결 과정
	
	1. calico node 0/1 문제 발생
		: 방화벽 문제인줄 알고 방화벽 해제 했지만 계속 같은 문제 발생
		  → 가상머신 Network를 Bridge로 설정하지 않고 NAT로 한 것이 원인

**2022 / 05 / 04**

- Elasticsearch 설치
- Logstash 설치
- Kibana 설치
- Spark 설치


▶ 오늘의 오류 발생 및 해결 과정

	1. apt install docker.io 설치 오류
		→ apt install containerd 실행하고 다시 apt install docker.io 진행하기

**2022 / 05 / 05**

- Ubuntu 이미지 위에 Hadoop 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. ssh 연결 오류
		→ vi /etc/hosts.allow 파일에 ssh:ALL:allow\sshd:ALL:allow 추가 후
                             service ssh restart 명령어 실행

	2. 도커 이미지 push 시 requeste denied 오류 발생
		→ docker login이 안되어 있거나 이미지 username과 docker hub id가 일치하지 않을 때 발생


**2022 / 05 / 07**

- Ubuntu + Hadoop 이미지 위에 Spark 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. bash : start command not found
		→ .bashrc 에 환경변수 설정을 안넣어줘서 발생하는 오류

**2022 / 05 / 08**

- Ubuntu + Hadoop + Spark 이미지 위에 Zepplin 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. wget으로 zeppelin 파일을 다운받을 때 root 디렉토리에 저장하지 않아서 경로 설정에 충돌 발생 

	2. 컨테이너 자체를 접속할 때 포트포워딩을 하고 접속을 하면 되는데 디플로이먼트로 생성 후 포트포워딩을 어떻게 해야할지 생각해보기  
